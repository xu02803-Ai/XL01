import OpenAI from 'openai';
import { NextResponse } from 'next/server';

// åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ŒæŒ‡å‘é˜¿é‡Œäº‘åƒé—®çš„å…¼å®¹ç«¯ç‚¹
const openai = new OpenAI({
  apiKey: process.env.DASHSCOPE_API_KEY || process.env.QWEN_API_KEY,
  baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
});

/**
 * POST /api/qwen/chat
 * 
 * æœ€ä½³å®è·µï¼šä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼è°ƒç”¨åƒé—®
 * 
 * è¯·æ±‚ä½“:
 * {
 *   "messages": [
 *     { "role": "user", "content": "ä½ å¥½" }
 *   ],
 *   "model": "qwen-plus" // å¯é€‰ï¼Œé»˜è®¤ qwen-plus
 * }
 * 
 * æ³¨æ„ï¼šVercel Free ç‰ˆæœ‰ 10 ç§’è¶…æ—¶é™åˆ¶
 * å¦‚æœä½¿ç”¨ qwen-maxï¼Œå»ºè®®å¯ç”¨æµå¼è¾“å‡º (stream: true)
 */
export async function POST(req: Request) {
  try {
    const body = await req.json();
    const { messages, model = 'qwen-plus', stream = false } = body;

    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: 'messages array is required' },
        { status: 400 }
      );
    }

    console.log(`ğŸš€ Calling Qwen (${model}) with ${messages.length} messages`);

    const response = await openai.chat.completions.create({
      model: model,
      messages: messages,
      temperature: 0.7,
      top_p: 0.8,
      max_tokens: 2000,
      stream: stream,
    });

    if (stream) {
      // å¤„ç†æµå¼å“åº”
      const stream = response as any;
      return new Response(stream.toReadableStream());
    } else {
      // å¤„ç†æ™®é€šå“åº”
      return NextResponse.json({
        success: true,
        message: response.choices[0].message,
        model: model,
        usage: response.usage,
      });
    }
  } catch (error: any) {
    console.error('âŒ Qwen API Error:', error);
    
    // è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
    const errorDetails = {
      message: error.message,
      status: error.status,
      code: error.code,
    };

    // å¦‚æœæ˜¯è¶…æ—¶é”™è¯¯ï¼ˆVercel é™åˆ¶ï¼‰
    if (error.status === 504 || error.message?.includes('timeout')) {
      return NextResponse.json(
        {
          error: 'Request timeout (Vercel Free has 10s limit)',
          hint: 'Try using qwen-plus instead of qwen-max, or enable streaming for longer responses',
          details: errorDetails,
        },
        { status: 504 }
      );
    }

    // å¦‚æœæ˜¯ API å¯†é’¥é”™è¯¯
    if (error.status === 401) {
      return NextResponse.json(
        {
          error: 'Invalid or missing API key',
          hint: 'Check DASHSCOPE_API_KEY environment variable in Vercel',
          details: errorDetails,
        },
        { status: 401 }
      );
    }

    return NextResponse.json(
      {
        error: 'Failed to call Qwen API',
        details: errorDetails,
      },
      { status: error.status || 500 }
    );
  }
}

/**
 * GET /api/qwen/chat
 * 
 * å¿«é€Ÿæµ‹è¯•ç«¯ç‚¹
 */
export async function GET(req: Request) {
  const { searchParams } = new URL(req.url);
  const prompt = searchParams.get('prompt') || 'ä½ å¥½';
  const model = searchParams.get('model') || 'qwen-plus';

  try {
    const response = await openai.chat.completions.create({
      model: model,
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 1000,
    });

    return NextResponse.json({
      success: true,
      prompt: prompt,
      response: response.choices[0].message.content,
      model: model,
    });
  } catch (error: any) {
    return NextResponse.json(
      { error: error.message },
      { status: error.status || 500 }
    );
  }
}
